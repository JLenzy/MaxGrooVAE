{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNtquLL_5VEs"
   },
   "source": [
    "To open this notebook in Colab visit https://goo.gl/magenta/groovae-colab\n",
    "\n",
    "<img src=\"https://magenta-staging.tensorflow.org/assets/groovae/score-groove.png\" alt=\"GrooVAE Figure\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import note_seq\n",
    "from note_seq.protobuf import music_pb2\n",
    "\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "\n",
    "GROOVAE_2BAR_TAP_FIXED_VELOCITY=\"groovae_2bar_tap_fixed_velocity.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I47LxktGbwMF",
    "outputId": "c44768cd-e917-4bcc-ba53-6c402d39e972"
   },
   "outputs": [],
   "source": [
    "# If a sequence has notes at time before 0.0, scootch them up to 0\n",
    "def start_notes_at_0(s):\n",
    "    for n in s.notes:\n",
    "        if n.start_time < 0:\n",
    "            n.end_time -= n.start_time\n",
    "            n.start_time = 0\n",
    "    return s\n",
    "\n",
    "# Some midi files come by default from different instrument channels\n",
    "# Quick and dirty way to set midi files to be recognized as drums\n",
    "def set_to_drums(ns):\n",
    "    for n in ns.notes:\n",
    "        n.instrument=9\n",
    "        n.is_drum = True\n",
    "        \n",
    "# quickly change the tempo of a midi sequence and adjust all notes\n",
    "def change_tempo(note_sequence, new_tempo):\n",
    "    new_sequence = copy.deepcopy(note_sequence)\n",
    "    ratio = note_sequence.tempos[0].qpm / new_tempo\n",
    "    for note in new_sequence.notes:\n",
    "        note.start_time = note.start_time * ratio\n",
    "        note.end_time = note.end_time * ratio\n",
    "    new_sequence.tempos[0].qpm = new_tempo\n",
    "    return new_sequence\n",
    "\n",
    "# Destructively quantize a midi sequence\n",
    "def flatten_quantization(s):\n",
    "    beat_length = 60. / s.tempos[0].qpm\n",
    "    step_length = beat_length / 4 #s.quantization_info.steps_per_quarter\n",
    "    new_s = copy.deepcopy(s)\n",
    "    for note in new_s.notes:\n",
    "        note.start_time = step_length * note.quantized_start_step\n",
    "        note.end_time = step_length * note.quantized_end_step\n",
    "    return new_s\n",
    "\n",
    "# Calculate quantization steps but do not remove microtiming\n",
    "def quantize(s, steps_per_quarter=4):\n",
    "    return note_seq.sequences_lib.quantize_note_sequence(s,steps_per_quarter)\n",
    "\n",
    "def add_silent_note(note_sequence, num_bars):\n",
    "    tempo = note_sequence.tempos[0].qpm\n",
    "    length = 60/tempo * 4 * num_bars\n",
    "    note_sequence.notes.add(\n",
    "        instrument=9, pitch=42, velocity=0, start_time=length-0.02, \n",
    "        end_time=length-0.01, is_drum=True)\n",
    "\n",
    "def is_4_4(s):\n",
    "    ts = s.time_signatures[0]\n",
    "    return (ts.numerator == 4 and ts.denominator ==4)\n",
    "\n",
    "# quick method for turning a drumbeat into a tapped rhythm\n",
    "def get_tapped_2bar(s, velocity=85, ride=False):\n",
    "    new_s = dc_tap.from_tensors(dc_tap.to_tensors(s).inputs)[0]\n",
    "    new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
    "    if velocity != 0:\n",
    "        for n in new_s.notes:\n",
    "            n.velocity = velocity\n",
    "    if ride:\n",
    "        for n in new_s.notes:\n",
    "            n.pitch = 42\n",
    "    return new_s\n",
    "\n",
    "def drumify(s, model, temperature=1.0): \n",
    "    encoding, mu, sigma = model.encode([s])\n",
    "    decoded = model.decode(encoding, length=32, temperature=temperature)\n",
    "    return decoded[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 10:36:59.592528: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n",
      "2022-03-16 10:37:05.453698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 10:37:05.462630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-16 10:37:05.462650: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-16 10:37:05.463174: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2039\n"
     ]
    }
   ],
   "source": [
    "# Load MIDI files from GMD with MIDI only (no audio) as a tf.data.Dataset\n",
    "dataset_2bar = tfds.as_numpy(tfds.load(\n",
    "                name=\"groove/2bar-midionly\",\n",
    "                split=tfds.Split.VALIDATION,\n",
    "                try_gcs=True))\n",
    "\n",
    "dev_sequences = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_2bar]\n",
    "_ = [set_to_drums(s) for s in dev_sequences]\n",
    "dev_sequences = [s for s in dev_sequences if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n",
    "print(len(dev_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPJuKYs0u7f4"
   },
   "source": [
    "# Tap2Drum: Generate a beat from any rhythm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxkHBd_uGFNP"
   },
   "source": [
    "While the Groove model works by removing the micro-timing and velocity information and learning to predict them from just the drum pattern, we can also go in the opposite direction.  Here, we take a representation of a Groove as input (in the form of a rhythm that can have precise timing but where drum categories are ignored) - and then generate drum beats that match the groove implied by this rhythm.  We trained this model by collapsing all drum hits from each beat in the training data to a single \"tapped\" rhythm, and then learning to decode full beats from that rhythm.  This allows us to input any rhythm we like through the precise onset timings in a \"tap\" and let the model decode our rhythm into a beat. We can even simply record taps as audio, or extract them from a recording of another instrument, rather than needing a midi controller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Control temperature with OSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtEPAgNISX5g"
   },
   "source": [
    "Here are a couple of examples using MIDI rhythms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "jFbxCIHRVSDl",
    "outputId": "73cb93d1-bd83-4b08-f256-47cd9078694b"
   },
   "outputs": [],
   "source": [
    "dc_tap = configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity'].data_converter\n",
    "\n",
    "groovae_2bar_tap = TrainedModel(config=configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity'],\n",
    "                                batch_size=1,\n",
    "                                checkpoint_dir_or_path=GROOVAE_2BAR_TAP_FIXED_VELOCITY)\n",
    "\n",
    "sequence_indices = [1111, 366]\n",
    "for i in sequence_indices:\n",
    "    s = start_notes_at_0(dev_sequences[i])\n",
    "    s = change_tempo(get_tapped_2bar(s, velocity=85, ride=True), dev_sequences[i].tempos[0].qpm)\n",
    "    h = change_tempo(drumify(s, groovae_2bar_tap), s.tempos[0].qpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = start_notes_at_0(dev_sequences[i])\n",
    "s = change_tempo(get_tapped_2bar(s, velocity=85, ride=True), dev_sequences[i].tempos[0].qpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IO Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantized_start_step, quantized_end_step  \n",
    "control_changes {\n",
    "  control_number: 4\n",
    "  control_value: 90\n",
    "  is_drum: true\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_list_to_midi_array(max_list, BPM):\n",
    "    beat_dur=60/BPM # in sec\n",
    "    midi_array=[]\n",
    "    for i in range((len(max_list)//3)):\n",
    "        start_step=float(max_list[3*i]) # in beats\n",
    "        end_step=float(max_list[3*i+1]) # in beats\n",
    "        vel=float(max_list[3*i+2])\n",
    "        start_time=start_step*beat_dur\n",
    "        end_time=end_step*beat_dur\n",
    "        midi_array.append([start_time,end_time,vel])\n",
    "    return np.array(midi_array)\n",
    "\n",
    "def make_tap_sequence_(tempo, midi_array, tpq=480):\n",
    "    note_sequence=music_pb2.NoteSequence()\n",
    "    note_sequence.tempos.add(qpm=tempo)\n",
    "    note_sequence.ticks_per_quarter=tpq\n",
    "    note_sequence.time_signatures.add(numerator=4, denominator=4)\n",
    "    note_sequence.key_signatures.add()\n",
    "    for onset_time, offset_time, onset_velocity in midi_array:\n",
    "        if onset_velocity:\n",
    "            note_sequence.notes.add(instrument=9, # Drum MIDI Program number\n",
    "                                    pitch=42, # Constant\n",
    "                                    is_drum=True,\n",
    "                                    velocity=int(onset_velocity),\n",
    "                                    start_time=onset_time,\n",
    "                                    end_time=offset_time)\n",
    "    note_sequence.total_time=2*4*(60/BPM) # 2bars\n",
    "    return note_sequence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slt=\"0. 0.03 120. 0.0625 0.0925 120. 0.125 0.155 120. 0.1875 0.2175 120. 0.25 0.28 120. 0.3125 0.3425 120. 0.375 0.405 0. 0.4375 0.4675 0. 0.5 0.53 0. 0.5625 0.5925 0. 0.625 0.655 0. 0.6875 0.7175 120. 0.75 0.78 0. 0.8125 0.8425 0. 0.875 0.905 120. 0.9375 0.9675 0. 1. 1.03 120. 1.0625 1.0925 120. 1.125 1.155 0. 1.1875 1.2175 0. 1.25 1.28 0. 1.3125 1.3425 0. 1.375 1.405 0. 1.4375 1.4675 0. 1.5 1.53 0. 1.5625 1.5925 0. 1.625 1.655 0. 1.6875 1.7175 0. 1.75 1.78 120. 1.8125 1.8425 120. 1.875 1.905 120. 1.9375 1.9675 120.\".split(' ')\n",
    "\n",
    "BPM=110\n",
    "midi_array=max_list_to_midi_array(slt, BPM)\n",
    "len(midi_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "64.0\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "BPM=120\n",
    "\n",
    "steps_per_quarter=4\n",
    "steps_per_bar=16\n",
    "total_bars=2\n",
    "lst=[]\n",
    "for s in range(steps_per_bar*total_bars):\n",
    "    lst.append([s/steps_per_quarter, (s+1)/steps_per_quarter, 120])\n",
    "\n",
    "midi_array=max_list_to_midi_array([l for ls in lst for l in ls], BPM)   \n",
    "\n",
    "note_sequence=make_tap_sequence_(BPM, midi_array)\n",
    "note_sequence=quantize(note_sequence, steps_per_quarter=16)\n",
    "set_to_drums(note_sequence)\n",
    "print(note_sequence.notes[-1].quantized_end_step)\n",
    "print(note_seq.steps_per_bar_in_quantized_sequence(note_sequence))\n",
    "if is_4_4(note_sequence) and len(note_sequence.notes) > 0 and note_sequence.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(note_sequence):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence=quantize(make_tap_sequence_(BPM, midi_array))\n",
    "note_sequence=start_notes_at_0(note_sequence)\n",
    "s=get_tapped_2bar(note_sequence, velocity=85, ride=True)\n",
    "#dc_tap.to_tensors(note_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_midi(midi_array, BPM):\n",
    "    \"\"\"Creates a pretty midi file from a midi_array.\"\"\"\n",
    "    midi=pretty_midi.PrettyMIDI(initial_tempo=BPM)\n",
    "    cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "    cello = pretty_midi.Instrument(program=cello_program)\n",
    "    for onset_time, offset_time, onset_velocity in midi_array:\n",
    "        if onset_velocity>0:\n",
    "            cello.notes.append(\n",
    "                pretty_midi.Note(\n",
    "                    velocity=85,#int(onset_velocity),\n",
    "                    pitch=42,\n",
    "                    start=onset_time,\n",
    "                    end=offset_time\n",
    "                )\n",
    "            )\n",
    "    midi.instruments.append(cello)\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPM=120\n",
    "midi_array=max_list_to_midi_array(slt, BPM)\n",
    "midi=create_pretty_midi(midi_array, BPM)\n",
    "\n",
    "note_sequence=start_notes_at_0(add_silent_note(note_seq.midi_to_note_sequence(midi),2))\n",
    "q_note_sequence=quantize(note_sequence)\n",
    "set_to_drums(q_note_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_note_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.instruments[0].notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_sequence=note_seq.midi_to_note_sequence(midi)\n",
    "q_note_sequence=quantize(note_sequence)\n",
    "set_to_drums(q_note_sequence)\n",
    "\n",
    "s=change_tempo(get_tapped_2bar(q_note_sequence, velocity=85, ride=True), q_note_sequence.tempos[0].qpm)\n",
    "h=change_tempo(drumify(s, groovae_2bar_tap), s.tempos[0].qpm)\n",
    "##dc_tap.to_tensors(q_note_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CNtquLL_5VEs",
    "yPY395Uo-y9f",
    "KLwr71jntKdP",
    "ylJ8BX1cu0Cn",
    "JPJuKYs0u7f4",
    "1rylVpq0vB-3"
   ],
   "name": "GrooVAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
