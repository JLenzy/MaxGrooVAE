{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNtquLL_5VEs"
   },
   "source": [
    "To open this notebook in Colab visit https://goo.gl/magenta/groovae-colab\n",
    "\n",
    "<img src=\"https://magenta-staging.tensorflow.org/assets/groovae/score-groove.png\" alt=\"GrooVAE Figure\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import librosa\n",
    "import note_seq\n",
    "from note_seq.protobuf import music_pb2\n",
    "\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "\n",
    "# Colab/Notebook specific stuff\n",
    "import IPython.display\n",
    "\n",
    "GROOVAE_2BAR_TAP_FIXED_VELOCITY=\"groovae_2bar_tap_fixed_velocity.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I47LxktGbwMF",
    "outputId": "c44768cd-e917-4bcc-ba53-6c402d39e972"
   },
   "outputs": [],
   "source": [
    "# If a sequence has notes at time before 0.0, scootch them up to 0\n",
    "def start_notes_at_0(s):\n",
    "  for n in s.notes:\n",
    "      if n.start_time < 0:\n",
    "          n.end_time -= n.start_time\n",
    "          n.start_time = 0\n",
    "  return s\n",
    "\n",
    "# Some midi files come by default from different instrument channels\n",
    "# Quick and dirty way to set midi files to be recognized as drums\n",
    "def set_to_drums(ns):\n",
    "  for n in ns.notes:\n",
    "    n.instrument=9\n",
    "    n.is_drum = True\n",
    "    \n",
    "def unset_to_drums(ns):\n",
    "  for note in ns.notes:\n",
    "    note.is_drum=False\n",
    "    note.instrument=0\n",
    "  return ns\n",
    "\n",
    "# quickly change the tempo of a midi sequence and adjust all notes\n",
    "def change_tempo(note_sequence, new_tempo):\n",
    "  new_sequence = copy.deepcopy(note_sequence)\n",
    "  ratio = note_sequence.tempos[0].qpm / new_tempo\n",
    "  for note in new_sequence.notes:\n",
    "    note.start_time = note.start_time * ratio\n",
    "    note.end_time = note.end_time * ratio\n",
    "  new_sequence.tempos[0].qpm = new_tempo\n",
    "  return new_sequence\n",
    "\n",
    "# Load some configs to be used later\n",
    "dc_tap = configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity'].data_converter\n",
    "dc_quantize = configs.CONFIG_MAP['groovae_2bar_humanize'].data_converter\n",
    "\n",
    "# quick method for removing microtiming and velocity from a sequence\n",
    "def get_quantized_2bar(s, velocity=0):\n",
    "  new_s = dc_quantize.from_tensors(dc_quantize.to_tensors(s).inputs)[0]\n",
    "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
    "  if velocity != 0:\n",
    "    for n in new_s.notes:\n",
    "      n.velocity = velocity\n",
    "  return new_s\n",
    "\n",
    "# quick method for turning a drumbeat into a tapped rhythm\n",
    "def get_tapped_2bar(s, velocity=85, ride=False):\n",
    "  new_s = dc_tap.from_tensors(dc_tap.to_tensors(s).inputs)[0]\n",
    "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
    "  if velocity != 0:\n",
    "    for n in new_s.notes:\n",
    "      n.velocity = velocity\n",
    "  if ride:\n",
    "    for n in new_s.notes:\n",
    "      n.pitch = 42\n",
    "  return new_s\n",
    "\n",
    "# Calculate quantization steps but do not remove microtiming\n",
    "def quantize(s, steps_per_quarter=4):\n",
    "  return note_seq.sequences_lib.quantize_note_sequence(s,steps_per_quarter)\n",
    "\n",
    "# Destructively quantize a midi sequence\n",
    "def flatten_quantization(s):\n",
    "  beat_length = 60. / s.tempos[0].qpm\n",
    "  step_length = beat_length / 4 #s.quantization_info.steps_per_quarter\n",
    "  new_s = copy.deepcopy(s)\n",
    "  for note in new_s.notes:\n",
    "    note.start_time = step_length * note.quantized_start_step\n",
    "    note.end_time = step_length * note.quantized_end_step\n",
    "  return new_s\n",
    "\n",
    "# Calculate how far off the beat a note is\n",
    "def get_offset(s, note_index):\n",
    "  q_s = flatten_quantization(quantize(s))\n",
    "  true_onset = s.notes[note_index].start_time\n",
    "  quantized_onset = q_s.notes[note_index].start_time\n",
    "  diff = quantized_onset - true_onset\n",
    "  beat_length = 60. / s.tempos[0].qpm\n",
    "  step_length = beat_length / 4#q_s.quantization_info.steps_per_quarter\n",
    "  offset = diff/step_length\n",
    "  return offset\n",
    "\n",
    "def is_4_4(s):\n",
    "  ts = s.time_signatures[0]\n",
    "  return (ts.numerator == 4 and ts.denominator ==4)\n",
    "\n",
    "def preprocess_2bar(s):\n",
    "  return dc_quantize.from_tensors(dc_quantize.to_tensors(s).outputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIDI files from GMD with MIDI only (no audio) as a tf.data.Dataset\n",
    "dataset_2bar = tfds.as_numpy(tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.VALIDATION,\n",
    "    try_gcs=True))\n",
    "\n",
    "dev_sequences = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_2bar]\n",
    "_ = [set_to_drums(s) for s in dev_sequences]\n",
    "dev_sequences = [s for s in dev_sequences if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n",
    "print(len(dev_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPJuKYs0u7f4"
   },
   "source": [
    "# Tap2Drum: Generate a beat from any rhythm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxkHBd_uGFNP"
   },
   "source": [
    "While the Groove model works by removing the micro-timing and velocity information and learning to predict them from just the drum pattern, we can also go in the opposite direction.  Here, we take a representation of a Groove as input (in the form of a rhythm that can have precise timing but where drum categories are ignored) - and then generate drum beats that match the groove implied by this rhythm.  We trained this model by collapsing all drum hits from each beat in the training data to a single \"tapped\" rhythm, and then learning to decode full beats from that rhythm.  This allows us to input any rhythm we like through the precise onset timings in a \"tap\" and let the model decode our rhythm into a beat. We can even simply record taps as audio, or extract them from a recording of another instrument, rather than needing a midi controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "au0HjIkZuBW4",
    "outputId": "9b75e203-a51d-4663-abad-54442617aa3c"
   },
   "outputs": [],
   "source": [
    "#def make_click_track(s):\n",
    "#  last_note_time = max([n.start_time for n in s.notes])\n",
    "#  beat_length = 60. / s.tempos[0].qpm \n",
    "#  i = 0\n",
    "#  times = []\n",
    "#  while i*beat_length < last_note_time:\n",
    "#    times.append(i*beat_length)\n",
    "#    i += 1\n",
    "#  return librosa.clicks(times)\n",
    "\n",
    "def drumify(s, model, temperature=1.0): \n",
    "  encoding, mu, sigma = model.encode([s])\n",
    "  decoded = model.decode(encoding, length=32, temperature=temperature)\n",
    "  return decoded[0]\n",
    "\n",
    "def combine_sequences(seqs):\n",
    "  # assumes a list of 2 bar seqs with constant tempo\n",
    "  for i, seq in enumerate(seqs):\n",
    "    shift_amount = i*(60 / seqs[0].tempos[0].qpm * 4 * 2)\n",
    "    if shift_amount > 0:\n",
    "      seqs[i] = note_seq.sequences_lib.shift_sequence_times(seq, shift_amount)\n",
    "  return note_seq.sequences_lib.concatenate_sequences(seqs)\n",
    "\n",
    "def combine_sequences_with_lengths(sequences, lengths):\n",
    "  seqs = copy.deepcopy(sequences)\n",
    "  total_shift_amount = 0\n",
    "  for i, seq in enumerate(seqs):\n",
    "    if i == 0:\n",
    "      shift_amount = 0\n",
    "    else:\n",
    "      shift_amount = lengths[i-1]\n",
    "    total_shift_amount += shift_amount\n",
    "    if total_shift_amount > 0:\n",
    "      seqs[i] = note_seq.sequences_lib.shift_sequence_times(seq, total_shift_amount)\n",
    "  combined_seq = music_pb2.NoteSequence()\n",
    "  for i in range(len(seqs)):\n",
    "    tempo = combined_seq.tempos.add()\n",
    "    tempo.qpm = seqs[i].tempos[0].qpm\n",
    "    tempo.time = sum(lengths[0:i-1])\n",
    "    for note in seqs[i].notes:\n",
    "      combined_seq.notes.extend([copy.deepcopy(note)])\n",
    "  return combined_seq\n",
    "\n",
    "# Allow encoding of a sequence that has no extracted examples\n",
    "# by adding a quiet note after the desired length of time\n",
    "def add_silent_note(note_sequence, num_bars):\n",
    "  tempo = note_sequence.tempos[0].qpm\n",
    "  length = 60/tempo * 4 * num_bars\n",
    "  note_sequence.notes.add(\n",
    "    instrument=9, pitch=42, velocity=0, start_time=length-0.02, \n",
    "    end_time=length-0.01, is_drum=True)\n",
    "  \n",
    "def get_bar_length(note_sequence):\n",
    "  tempo = note_sequence.tempos[0].qpm\n",
    "  return 60/tempo * 4\n",
    "\n",
    "def sequence_is_shorter_than_full(note_sequence):\n",
    "  return note_sequence.notes[-1].start_time < get_bar_length(note_sequence)\n",
    "\n",
    "def make_tap_sequence(tempo, onset_times, onset_frames, onset_velocities,\n",
    "                     velocity_threshold, start_time, end_time):\n",
    "  note_sequence = music_pb2.NoteSequence()\n",
    "  note_sequence.tempos.add(qpm=tempo)\n",
    "  for onset_vel, onset_time in zip(onset_velocities, onset_times):\n",
    "    if onset_vel > velocity_threshold and onset_time >= start_time and onset_time < end_time:  # filter quietest notes\n",
    "      note_sequence.notes.add(\n",
    "        instrument=9, pitch=42, is_drum=True,\n",
    "        velocity=onset_vel,  # model will use fixed velocity here\n",
    "        start_time=onset_time - start_time,\n",
    "        end_time=onset_time -start_time + 0.01\n",
    "      )\n",
    "  return note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtEPAgNISX5g"
   },
   "source": [
    "Here are a couple of examples using MIDI rhythms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "jFbxCIHRVSDl",
    "outputId": "73cb93d1-bd83-4b08-f256-47cd9078694b"
   },
   "outputs": [],
   "source": [
    "config_2bar_tap = configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity']\n",
    "groovae_2bar_tap = TrainedModel(config_2bar_tap, 1, checkpoint_dir_or_path=GROOVAE_2BAR_TAP_FIXED_VELOCITY)\n",
    "\n",
    "sequence_indices = [1111, 366]\n",
    "for i in sequence_indices:\n",
    "  s = start_notes_at_0(dev_sequences[i])\n",
    "  s = change_tempo(get_tapped_2bar(s, velocity=85, ride=True), dev_sequences[i].tempos[0].qpm)\n",
    "  h = change_tempo(drumify(s, groovae_2bar_tap), s.tempos[0].qpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt=\"0. 0.03 120. 0.0625 0.0925 0. 0.125 0.155 0. 0.1875 0.2175 0. 0.25 0.28 0. 0.3125 0.3425 0. 0.375 0.405 0. 0.4375 0.4675 0. 0.5 0.53 0. 0.5625 0.5925 0. 0.625 0.655 0. 0.6875 0.7175 0. 0.75 0.78 0. 0.8125 0.8425 0. 0.875 0.905 0. 0.9375 0.9675 0. 1. 1.03 120. 1.0625 1.0925 0. 1.125 1.155 0. 1.1875 1.2175 0. 1.25 1.28 0. 1.3125 1.3425 0. 1.375 1.405 0. 1.4375 1.4675 0. 1.5 1.53 0. 1.5625 1.5925 0. 1.625 1.655 0. 1.6875 1.7175 0. 1.75 1.78 0. 1.8125 1.8425 0. 1.875 1.905 0. 1.9375 1.9675 0.\".split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_array=[]\n",
    "for i in range((len(slt)//3)-1):\n",
    "    #print(slt[3*i:3*(i+1)])\n",
    "    start=float(slt[3*i])\n",
    "    end=float(slt[3*i+1])\n",
    "    vel=float(slt[3*i+2])\n",
    "    midi_array.append([start,end,vel])\n",
    "midi_array=np.array(midi_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_array"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CNtquLL_5VEs",
    "yPY395Uo-y9f",
    "KLwr71jntKdP",
    "ylJ8BX1cu0Cn",
    "JPJuKYs0u7f4",
    "1rylVpq0vB-3"
   ],
   "name": "GrooVAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
