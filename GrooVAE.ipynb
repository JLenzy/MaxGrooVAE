{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNtquLL_5VEs"
   },
   "source": [
    "To open this notebook in Colab visit https://goo.gl/magenta/groovae-colab\n",
    "\n",
    "<img src=\"https://magenta-staging.tensorflow.org/assets/groovae/score-groove.png\" alt=\"GrooVAE Figure\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "<ol>\n",
    "  <li><strike>NN to Max</strike></li>\n",
    "  <li><strike>Python Module Everything</strike></li>\n",
    "  <li><strike>Osc Integration</strike></li>\n",
    "  <li>Preserve Microtiming</li>\n",
    "  <li>Control temperature with OSC</li>\n",
    "  <li>What are mu, sigma?</li>\n",
    "  <li>tpq=220</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#import tensorflow_datasets as tfds\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "\n",
    "from groovae_max import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load MIDI files from GMD with MIDI only (no audio) as a tf.data.Dataset\n",
    "#dataset_2bar = tfds.as_numpy(tfds.load(\n",
    "#                name=\"groove/2bar-midionly\",\n",
    "#                split=tfds.Split.VALIDATION,\n",
    "#                try_gcs=True))\n",
    "#\n",
    "#dev_sequences = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_2bar]\n",
    "#_ = [set_to_drums(s) for s in dev_sequences]\n",
    "#dev_sequences = [s for s in dev_sequences if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n",
    "#print(len(dev_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPJuKYs0u7f4"
   },
   "source": [
    "# Tap2Drum: Generate a beat from any rhythm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxkHBd_uGFNP"
   },
   "source": [
    "While the Groove model works by removing the micro-timing and velocity information and learning to predict them from just the drum pattern, we can also go in the opposite direction.  Here, we take a representation of a Groove as input (in the form of a rhythm that can have precise timing but where drum categories are ignored) - and then generate drum beats that match the groove implied by this rhythm.  We trained this model by collapsing all drum hits from each beat in the training data to a single \"tapped\" rhythm, and then learning to decode full beats from that rhythm.  This allows us to input any rhythm we like through the precise onset timings in a \"tap\" and let the model decode our rhythm into a beat. We can even simply record taps as audio, or extract them from a recording of another instrument, rather than needing a midi controller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtEPAgNISX5g"
   },
   "source": [
    "Here are a couple of examples using MIDI rhythms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "jFbxCIHRVSDl",
    "outputId": "73cb93d1-bd83-4b08-f256-47cd9078694b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, GrooveLstmDecoder, and hparams:\n",
      "{'max_seq_len': 32, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 0.3, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [512]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [256, 256]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  name=name),\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  initializer=tf.constant_initializer(0.0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:446: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 13:44:54.209109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 13:44:54.217790: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-16 13:44:54.217814: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not call `graph_parents`.\n",
      "INFO:tensorflow:Unbundling checkpoint.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpywf7hcoz/groovae_2bar_tap_fixed_velocity/model.ckpt-3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n",
      "/home/oguz/anaconda3/envs/cc/lib/python3.7/site-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n",
      "2022-03-16 13:44:54.498714: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "groovae_2bar_tap = TrainedModel(config=configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity'],\n",
    "                                batch_size=1,\n",
    "                                checkpoint_dir_or_path=GROOVAE_2BAR_TAP_FIXED_VELOCITY)\n",
    "\n",
    "#sequence_indices = [1111, 366]\n",
    "#for i in sequence_indices:\n",
    "#    s = start_notes_at_0(dev_sequences[i])\n",
    "#    s = change_tempo(get_tapped_2bar(s, velocity=85, ride=True), dev_sequences[i].tempos[0].qpm)\n",
    "#    h = change_tempo(drumify(s, groovae_2bar_tap), s.tempos[0].qpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IO Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantized_start_step, quantized_end_step  \n",
    "control_changes {\n",
    "  control_number: 4\n",
    "  control_value: 90\n",
    "  is_drum: true\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lst=\"0. 0.03 120. 0.0625 0.0925 120. 0.125 0.155 120. 0.1875 0.2175 120. 0.25 0.28 120. 0.3125 0.3425 120. 0.375 0.405 0. 0.4375 0.4675 0. 0.5 0.53 0. 0.5625 0.5925 0. 0.625 0.655 0. 0.6875 0.7175 120. 0.75 0.78 0. 0.8125 0.8425 0. 0.875 0.905 120. 0.9375 0.9675 0. 1. 1.03 120. 1.0625 1.0925 120. 1.125 1.155 0. 1.1875 1.2175 0. 1.25 1.28 0. 1.3125 1.3425 0. 1.375 1.405 0. 1.4375 1.4675 0. 1.5 1.53 0. 1.5625 1.5925 0. 1.625 1.655 0. 1.6875 1.7175 0. 1.75 1.78 120. 1.8125 1.8425 120. 1.875 1.905 120. 1.9375 1.9675 120.\".split(' ')\n",
    "\n",
    "BPM=120\n",
    "# Convert max list to a readable format\n",
    "midi_array=max_list_to_midi_array(max_lst, BPM)\n",
    "len(midi_array)\n",
    "# Convert it into the pre-NN input format\n",
    "note_sequence=make_tap_sequence(midi_array, BPM)\n",
    "note_sequence=quantize(note_sequence)\n",
    "set_to_drums(note_sequence)\n",
    "# Convert to NN input format\n",
    "s=copy.deepcopy(note_sequence)\n",
    "s=start_notes_at_0(s)\n",
    "s=change_tempo(get_tapped_2bar(s, velocity=VELOCITY, ride=True), BPM)\n",
    "assert BPM==s.tempos[0].qpm, 'Tempo conversion failed at tapped bar creation'\n",
    "# Get NN prediction\n",
    "h=change_tempo(drumify(s, groovae_2bar_tap), BPM)\n",
    "assert BPM==h.tempos[0].qpm, 'Tempo conversion failed at NN creation'\n",
    "# Convert to Max array\n",
    "MAX_array=NN_output_to_Max(h, BPM, beat_quantization_division=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.25    , 18.      , 36.      ],\n",
       "       [ 0.015625,  0.25    , 24.      , 42.      ],\n",
       "       [ 0.25    ,  0.25    , 28.      , 42.      ],\n",
       "       [ 0.25    ,  0.25    ,  0.      , 49.      ],\n",
       "       [ 0.484375,  0.25    , 17.      , 36.      ],\n",
       "       [ 0.484375,  0.25    , 11.      , 38.      ],\n",
       "       [ 0.71875 ,  0.25    , 50.      , 42.      ],\n",
       "       [ 0.984375,  0.25    , 15.      , 38.      ],\n",
       "       [ 1.      ,  0.25    , 34.      , 42.      ],\n",
       "       [ 1.234375,  0.25    , 14.      , 38.      ],\n",
       "       [ 1.5     ,  0.25    , 12.      , 38.      ],\n",
       "       [ 1.984375,  0.25    , 35.      , 38.      ],\n",
       "       [ 2.25    ,  0.25    , 27.      , 38.      ],\n",
       "       [ 2.734375,  0.25    ,  1.      , 50.      ],\n",
       "       [ 2.984375,  0.25    , 25.      , 38.      ],\n",
       "       [ 3.703125,  0.25    , 18.      , 38.      ],\n",
       "       [ 3.96875 ,  0.25    , 45.      , 36.      ],\n",
       "       [ 3.984375,  0.25    , 54.      , 49.      ],\n",
       "       [ 4.984375,  0.25    , 58.      , 42.      ],\n",
       "       [ 5.984375,  0.25    , 41.      , 38.      ],\n",
       "       [ 6.25    ,  0.25    , 23.      , 38.      ],\n",
       "       [ 6.28125 ,  0.25    ,  7.      , 42.      ],\n",
       "       [ 6.984375,  0.25    , 42.      , 42.      ],\n",
       "       [ 7.265625,  0.25    , 11.      , 38.      ],\n",
       "       [ 7.25    ,  0.25    ,  6.      , 42.      ],\n",
       "       [ 7.25    ,  0.25    ,  1.      , 50.      ],\n",
       "       [ 7.703125,  0.25    , 24.      , 38.      ],\n",
       "       [ 7.703125,  0.25    , 12.      , 42.      ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_array"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CNtquLL_5VEs",
    "yPY395Uo-y9f",
    "KLwr71jntKdP",
    "ylJ8BX1cu0Cn",
    "JPJuKYs0u7f4",
    "1rylVpq0vB-3"
   ],
   "name": "GrooVAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cc",
   "language": "python",
   "name": "cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
